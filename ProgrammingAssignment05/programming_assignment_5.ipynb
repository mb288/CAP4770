{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940d65bc-011d-4762-8f7c-d628f2a81bcd",
   "metadata": {},
   "source": [
    "# Programming Assignment #5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ccdfcc-83fa-4eb2-a3b7-9671f72157e8",
   "metadata": {},
   "source": [
    "## Association rule mining \n",
    "\n",
    "The market basket transactions dataset (transactions_data.txt)contains list of items purchased by customer in each transaction.\n",
    "\n",
    "- load the transaction dataset file\n",
    "- use minimum support = 0.2 and use_colname=True in apriori method \n",
    "- select metric as confidence in association rules\n",
    "- use minimum threshold = 0.5\n",
    "\n",
    "Ex: If the minimum support is 0.4, the metric is confidence and minimum threshold is 0.5 then some of the outputs are: \n",
    "- the least frequency of frequent 1-itemset is ['Queso'].\n",
    "- the support, confidence, and lift of rule, ['Queso'] -> ['Tortilla chips'] are:\n",
    "  - consequent support = 0.7\n",
    "  - support = 0.4\n",
    "  - confidence = 1.00\n",
    "  - lift = 1.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef59b37-5429-42b9-a45c-56ad45a7968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3305df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from mlxtend) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from mlxtend) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from mlxtend) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from mlxtend) (3.7.5)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/pycaret_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caeaf8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Lime', 'Queso', 'Salsa', 'Salt', 'Tortilla chips'],\n",
       " ['Ranch dip', 'Salsa', 'Tortilla chips'],\n",
       " ['Queso', 'Tortilla chips'],\n",
       " ['Potato chips', 'Ranch dip'],\n",
       " ['Salsa', 'Tortilla chips'],\n",
       " ['Queso', 'Salsa', 'Tortilla chips'],\n",
       " ['Pita chips', 'Ranch dip'],\n",
       " ['Guacamole', 'Tortilla chips'],\n",
       " ['Guacamole', 'Queso', 'Salsa', 'Tortilla chips'],\n",
       " ['Pita chips', 'Salsa']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the transactions dataset \n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Loading the data\n",
    "def load_dataset(path_to_data):\n",
    "    transactions = []\n",
    "    with open(path_to_data, 'r') as fid:\n",
    "        for line in fid:\n",
    "            transaction = line.strip().split(',')\n",
    "            transactions.append(transaction)\n",
    "    return transactions\n",
    "\n",
    "path_to_data = \"transactions_data.txt\"  \n",
    "dataset = load_dataset(path_to_data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4cadf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "    support                        itemsets\n",
      "0       0.2                     (Guacamole)\n",
      "1       0.2                    (Pita chips)\n",
      "2       0.4                         (Queso)\n",
      "3       0.3                     (Ranch dip)\n",
      "4       0.6                         (Salsa)\n",
      "5       0.7                (Tortilla chips)\n",
      "6       0.2     (Guacamole, Tortilla chips)\n",
      "7       0.3                  (Salsa, Queso)\n",
      "8       0.4         (Tortilla chips, Queso)\n",
      "9       0.5         (Salsa, Tortilla chips)\n",
      "10      0.3  (Salsa, Tortilla chips, Queso)\n",
      "\n",
      "Association Rules:\n",
      "                antecedents              consequents  antecedent support  \\\n",
      "0               (Guacamole)         (Tortilla chips)                 0.2   \n",
      "1                   (Salsa)                  (Queso)                 0.6   \n",
      "2                   (Queso)                  (Salsa)                 0.4   \n",
      "3          (Tortilla chips)                  (Queso)                 0.7   \n",
      "4                   (Queso)         (Tortilla chips)                 0.4   \n",
      "5                   (Salsa)         (Tortilla chips)                 0.6   \n",
      "6          (Tortilla chips)                  (Salsa)                 0.7   \n",
      "7   (Salsa, Tortilla chips)                  (Queso)                 0.5   \n",
      "8            (Salsa, Queso)         (Tortilla chips)                 0.3   \n",
      "9   (Tortilla chips, Queso)                  (Salsa)                 0.4   \n",
      "10                  (Salsa)  (Tortilla chips, Queso)                 0.6   \n",
      "11                  (Queso)  (Salsa, Tortilla chips)                 0.4   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0                  0.7      0.2    1.000000  1.428571      0.06         inf   \n",
      "1                  0.4      0.3    0.500000  1.250000      0.06         1.2   \n",
      "2                  0.6      0.3    0.750000  1.250000      0.06         1.6   \n",
      "3                  0.4      0.4    0.571429  1.428571      0.12         1.4   \n",
      "4                  0.7      0.4    1.000000  1.428571      0.12         inf   \n",
      "5                  0.7      0.5    0.833333  1.190476      0.08         1.8   \n",
      "6                  0.6      0.5    0.714286  1.190476      0.08         1.4   \n",
      "7                  0.4      0.3    0.600000  1.500000      0.10         1.5   \n",
      "8                  0.7      0.3    1.000000  1.428571      0.09         inf   \n",
      "9                  0.6      0.3    0.750000  1.250000      0.06         1.6   \n",
      "10                 0.4      0.3    0.500000  1.250000      0.06         1.2   \n",
      "11                 0.5      0.3    0.750000  1.500000      0.10         2.0   \n",
      "\n",
      "    zhangs_metric  \n",
      "0        0.375000  \n",
      "1        0.500000  \n",
      "2        0.333333  \n",
      "3        1.000000  \n",
      "4        0.500000  \n",
      "5        0.400000  \n",
      "6        0.533333  \n",
      "7        0.666667  \n",
      "8        0.428571  \n",
      "9        0.333333  \n",
      "10       0.500000  \n",
      "11       0.555556  \n"
     ]
    }
   ],
   "source": [
    "# Transform the data to a format suitable for the apriori function\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply the apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)  \n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate the association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81071e13-02cb-40f2-8210-5e420bf572ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_env",
   "language": "python",
   "name": "pycaret_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
